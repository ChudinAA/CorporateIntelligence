[2025-04-03 15:12:23 +0000] [621] [ERROR] Error handling request
Traceback (most recent call last):
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/workers/sync.py", line 180, in handle_request
    resp.write_file(respiter)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/http/wsgi.py", line 393, in write_file
    if not self.sendfile(respiter):
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/http/wsgi.py", line 383, in sendfile
    self.sock.sendfile(respiter.filelike, offset=offset, count=nbytes)
  File "/nix/store/clx0mcir7qw8zk36zbr4jra789g3knf6-python3-3.11.10/lib/python3.11/socket.py", line 485, in sendfile
    return self._sendfile_use_sendfile(file, offset, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nix/store/clx0mcir7qw8zk36zbr4jra789g3knf6-python3-3.11.10/lib/python3.11/socket.py", line 365, in _sendfile_use_sendfile
    raise ValueError("non-blocking sockets are not supported")
ValueError: non-blocking sockets are not supported
server=cc4136bb-3a2e-4dfe-9d83-bc12a8031874-00-3kv1wzbjbc7l.janeway.replit.dev//socket.io/ client=172.31.128.28:34588 socket shutdown error: [Errno 9] Bad file descriptor[2025-04-03 15:12:39 +0000] [621] [ERROR] Socket error processing request.
Traceback (most recent call last):
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/workers/sync.py", line 134, in handle
    self.handle_request(listener, req, client, addr)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/workers/sync.py", line 192, in handle_request
    util.reraise(*sys.exc_info())
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/util.py", line 640, in reraise
    raise value
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/workers/sync.py", line 184, in handle_request
    resp.close()
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/http/wsgi.py", line 399, in close
    self.send_headers()
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/http/wsgi.py", line 330, in send_headers
    util.write(self.sock, util.to_bytestring(header_str, "latin-1"))
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/gunicorn/util.py", line 298, in write
    sock.sendall(data)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/eventlet/greenio/base.py", line 389, in sendall
    tail = self.send(data, flags)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/eventlet/greenio/base.py", line 383, in send
    return self._send_loop(self.fd.send, data, flags)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/eventlet/greenio/base.py", line 370, in _send_loop
    return send_method(data, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 9] Bad file descriptor
ERROR:llm_integration:Error generating embedding: Llama model must be created with embedding=True to call this method
Traceback (most recent call last):
  File "/home/runner/workspace/llm_integration.py", line 117, in get_embedding
    embedding = self.embedding_model.embed(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/llama_cpp/llama.py", line 1023, in embed
    raise RuntimeError(
RuntimeError: Llama model must be created with embedding=True to call this method